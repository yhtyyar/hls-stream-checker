#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ HLS –ø—Ä–æ–≤–µ—Ä–∫–∏

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–Ω–∞–ª–æ–≤ –∏ –æ–±—â—É—é —Å–≤–æ–¥–∫—É
–≤ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö: CSV –¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤, JSON –¥–ª—è API/—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞.
"""

import csv
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø—É—Ç–µ–π
DATA_DIR = Path("data")
CSV_DIR = DATA_DIR / "csv"
JSON_DIR = DATA_DIR / "json"

logger = logging.getLogger("data_exporter")


class OptimizedDataExporter:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ HLS –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    
    def __init__(self, session_start: datetime, session_end: Optional[datetime] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            session_start: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏
            session_end: –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è)
        """
        self.session_start = session_start
        self.session_end = session_end or datetime.now()
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å–µ—Å—Å–∏–∏
        self.session_id = self.session_start.strftime("%Y%m%d_%H%M%S")
        self.session_duration = (self.session_end - self.session_start).total_seconds()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        self._ensure_directories()
    
    def _ensure_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        DATA_DIR.mkdir(exist_ok=True)
        CSV_DIR.mkdir(exist_ok=True)
        JSON_DIR.mkdir(exist_ok=True)
    
    def export_channels_summary_csv(self, global_stats) -> Path:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–Ω–∞–ª–æ–≤ –≤ CSV (–¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)
        
        Args:
            global_stats: –û–±—ä–µ–∫—Ç GlobalStats —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É CSV —Ñ–∞–π–ª—É
        """
        # –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: –ø—Ä–µ—Ñ–∏–∫—Å_—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ_–≤—Ä–µ–º—è
        csv_filename = f"hls_channels_final_stats_{self.session_id}.csv"
        csv_path = CSV_DIR / csv_filename
        
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                '–≤—Ä–µ–º—è_–Ω–∞—á–∞–ª–∞_—Å–µ—Å—Å–∏–∏',
                '–≤—Ä–µ–º—è_–æ–∫–æ–Ω—á–∞–Ω–∏—è_—Å–µ—Å—Å–∏–∏',
                '–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_—Å–µ–∫—É–Ω–¥',
                '–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞–Ω–∞–ª–∞',
                'id_–∫–∞–Ω–∞–ª–∞',
                '–≤—Å–µ–≥–æ_—Å–µ–≥–º–µ–Ω—Ç–æ–≤',
                '—É—Å–ø–µ—à–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫',
                '–Ω–µ—É–¥–∞—á–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫',
                '–ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏',
                '–æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë',
                '—Å—Ä–µ–¥–Ω—è—è_—Å–∫–æ—Ä–æ—Å—Ç—å_–ú–ë_—Å',
                '–≤—Ä–µ–º—è_–ø—Ä–æ–≤–µ—Ä–∫–∏_—Å–µ–∫—É–Ω–¥',
                'master_url',
                'variant_url'
            ]
            
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for channel in global_stats.channels:
                if channel.total_segments > 0:  # –¢–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏
                    total_mb = channel.total_bytes / (1024 * 1024) if channel.total_bytes > 0 else 0
                    
                    row = {
                        '–≤—Ä–µ–º—è_–Ω–∞—á–∞–ª–∞_—Å–µ—Å—Å–∏–∏': self.session_start.strftime('%Y-%m-%d %H:%M:%S'),
                        '–≤—Ä–µ–º—è_–æ–∫–æ–Ω—á–∞–Ω–∏—è_—Å–µ—Å—Å–∏–∏': self.session_end.strftime('%Y-%m-%d %H:%M:%S'),
                        '–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_—Å–µ–∫—É–Ω–¥': round(self.session_duration, 1),
                        '–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞–Ω–∞–ª–∞': channel.channel_name,
                        'id_–∫–∞–Ω–∞–ª–∞': channel.channel_id,
                        '–≤—Å–µ–≥–æ_—Å–µ–≥–º–µ–Ω—Ç–æ–≤': channel.total_segments,
                        '—É—Å–ø–µ—à–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫': channel.successful_downloads,
                        '–Ω–µ—É–¥–∞—á–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫': channel.failed_downloads,
                        '–ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏': round(channel.success_rate, 2),
                        '–æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë': round(total_mb, 2),
                        '—Å—Ä–µ–¥–Ω—è—è_—Å–∫–æ—Ä–æ—Å—Ç—å_–ú–ë_—Å': round(channel.avg_download_speed, 3),
                        '–≤—Ä–µ–º—è_–ø—Ä–æ–≤–µ—Ä–∫–∏_—Å–µ–∫—É–Ω–¥': round(channel.duration, 1),
                        'master_url': channel.master_url,
                        'variant_url': channel.variant_url
                    }
                    writer.writerow(row)
        
        logger.info(f"üìà –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ CSV: {csv_path}")
        return csv_path
    
    def export_global_summary_csv(self, global_stats) -> Path:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–±—â—É—é —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ CSV (–¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)
        
        Args:
            global_stats: –û–±—ä–µ–∫—Ç GlobalStats —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É CSV —Ñ–∞–π–ª—É
        """
        csv_filename = f"hls_global_summary_{self.session_id}.csv"
        csv_path = CSV_DIR / csv_filename
        
        total_mb = global_stats.total_bytes / (1024 * 1024) if global_stats.total_bytes > 0 else 0
        avg_speed = (total_mb / self.session_duration) if self.session_duration > 0 else 0
        
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                '–≤—Ä–µ–º—è_–Ω–∞—á–∞–ª–∞_—Å–µ—Å—Å–∏–∏',
                '–≤—Ä–µ–º—è_–æ–∫–æ–Ω—á–∞–Ω–∏—è_—Å–µ—Å—Å–∏–∏',
                '–æ–±—â–∞—è_–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_—Å–µ–∫—É–Ω–¥',
                '–æ–±—â–µ–µ_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–∞–Ω–∞–ª–æ–≤',
                '—É—Å–ø–µ—à–Ω–æ_–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ_–∫–∞–Ω–∞–ª–æ–≤',
                '–≤—Å–µ–≥–æ_—Å–µ–≥–º–µ–Ω—Ç–æ–≤',
                '—É—Å–ø–µ—à–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫',
                '–Ω–µ—É–¥–∞—á–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫',
                '–æ–±—â–∏–π_–ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏',
                '–æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë',
                '—Å—Ä–µ–¥–Ω—è—è_—Å–∫–æ—Ä–æ—Å—Ç—å_–ú–ë_—Å'
            ]
            
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            row = {
                '–≤—Ä–µ–º—è_–Ω–∞—á–∞–ª–∞_—Å–µ—Å—Å–∏–∏': self.session_start.strftime('%Y-%m-%d %H:%M:%S'),
                '–≤—Ä–µ–º—è_–æ–∫–æ–Ω—á–∞–Ω–∏—è_—Å–µ—Å—Å–∏–∏': self.session_end.strftime('%Y-%m-%d %H:%M:%S'),
                '–æ–±—â–∞—è_–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_—Å–µ–∫—É–Ω–¥': round(self.session_duration, 1),
                '–æ–±—â–µ–µ_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–∞–Ω–∞–ª–æ–≤': global_stats.total_channels,
                '—É—Å–ø–µ—à–Ω–æ_–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ_–∫–∞–Ω–∞–ª–æ–≤': global_stats.completed_channels,
                '–≤—Å–µ–≥–æ_—Å–µ–≥–º–µ–Ω—Ç–æ–≤': global_stats.total_segments,
                '—É—Å–ø–µ—à–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫': global_stats.successful_downloads,
                '–Ω–µ—É–¥–∞—á–Ω—ã—Ö_–∑–∞–≥—Ä—É–∑–æ–∫': global_stats.failed_downloads,
                '–æ–±—â–∏–π_–ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏': round(global_stats.overall_success_rate, 2),
                '–æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë': round(total_mb, 2),
                '—Å—Ä–µ–¥–Ω—è—è_—Å–∫–æ—Ä–æ—Å—Ç—å_–ú–ë_—Å': round(avg_speed, 3)
            }
            writer.writerow(row)
        
        logger.info(f"üìä –û–±—â–∞—è —Å–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ CSV: {csv_path}")
        return csv_path
    
    def export_optimized_json(self, global_stats) -> Path:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON (–¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞/API)
        
        Args:
            global_stats: –û–±—ä–µ–∫—Ç GlobalStats —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É JSON —Ñ–∞–π–ª—É
        """
        json_filename = f"hls_api_report_{self.session_id}.json"
        json_path = JSON_DIR / json_filename
        
        # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è API
        api_data = {
            "analytics": {
                "overall_analysis": {
                    "success_rate": round(global_stats.overall_success_rate, 2),
                    "total_errors": global_stats.failed_downloads,
                    "error_distribution": global_stats.error_counts if hasattr(global_stats, 'error_counts') else {}
                }
            },
            "session": {
                "id": self.session_id,
                "start_time": self.session_start.isoformat(),
                "end_time": self.session_end.isoformat(),
                "duration_seconds": round(self.session_duration, 1),
                "export_timestamp": datetime.now().isoformat()
            },
            "summary": {
                "total_channels": global_stats.total_channels,
                "completed_channels": global_stats.completed_channels,
                "total_segments": global_stats.total_segments,
                "successful_downloads": global_stats.successful_downloads,
                "failed_downloads": global_stats.failed_downloads,
                "overall_success_rate": round(global_stats.overall_success_rate, 2),
                "total_data_mb": round(global_stats.total_bytes / (1024 * 1024), 2)
            },
            "channels": []
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–Ω–∞–ª–æ–≤
        for channel in global_stats.channels:
            if channel.total_segments > 0:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –æ—à–∏–±–∫–∞–º –¥–ª—è –∫–∞–Ω–∞–ª–∞
                error_stats = {}
                if hasattr(channel, 'error_counts'):
                    error_stats = {
                        "error_count": channel.failed_downloads,
                        "error_details": channel.error_counts
                    }
                
                channel_data = {
                    "id": channel.channel_id,
                    "name": channel.channel_name,
                    "stats": {
                        "total_segments": channel.total_segments,
                        "successful_downloads": channel.successful_downloads,
                        "failed_downloads": channel.failed_downloads,
                        "success_rate": round(channel.success_rate, 2),
                        "total_data_mb": round(
                            channel.total_bytes / (1024 * 1024), 
                            2
                        ),
                        "avg_speed_mbps": round(channel.avg_download_speed, 3),
                        "duration_seconds": round(channel.duration, 1),
                        "errors": error_stats
                    },
                    "urls": {
                        "master": channel.master_url,
                        "variant": channel.variant_url
                    }
                }
                api_data["channels"].append(channel_data)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        if api_data["channels"]:
            best_channel = max(api_data["channels"], key=lambda x: x["stats"]["success_rate"])
            worst_channel = min(api_data["channels"], key=lambda x: x["stats"]["success_rate"])
            
            # –û–±–Ω–æ–≤–ª—è–µ–º analytics —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            api_data["analytics"].update({
                "best_channel": {
                    "name": best_channel["name"],
                    "success_rate": best_channel["stats"]["success_rate"],
                    "errors": best_channel["stats"].get("errors", {})
                },
                "worst_channel": {
                    "name": worst_channel["name"],
                    "success_rate": worst_channel["stats"]["success_rate"],
                    "errors": worst_channel["stats"].get("errors", {})
                },
                "channels_analysis": [
                    {
                        "name": ch["name"],
                        "success_rate": ch["stats"]["success_rate"],
                        "errors": ch["stats"].get("errors", {})
                    }
                    for ch in sorted(
                        api_data["channels"],
                        key=lambda x: x["stats"]["success_rate"],
                        reverse=True
                    )
                ]
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        with open(json_path, 'w', encoding='utf-8') as jsonfile:
            json.dump(api_data, jsonfile, ensure_ascii=False, indent=2)
        
        logger.info(f"üöÄ API –æ—Ç—á–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ JSON: {json_path}")
        return json_path
    
    def export_final_statistics(self, global_stats) -> Dict[str, Path]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        
        Args:
            global_stats: –û–±—ä–µ–∫—Ç GlobalStats —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
        """
        logger.info("üöÄ –ù–∞—á–∞–ª–æ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        
        exported_files = {
            'channels_csv': self.export_channels_summary_csv(global_stats),
            'global_csv': self.export_global_summary_csv(global_stats),
            'api_json': self.export_optimized_json(global_stats)
        }
        
        logger.info("=" * 70)
        logger.info("üìÅ –≠–ö–°–ü–û–†–¢ –§–ò–ù–ê–õ–¨–ù–û–ô –°–¢–ê–¢–ò–°–¢–ò–ö–ò –ó–ê–í–ï–†–®–ï–ù!")
        logger.info("üìä –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        for file_type, file_path in exported_files.items():
            if 'csv' in file_type:
                logger.info(f"   üìà {file_type}: {file_path} (–¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)")
            else:
                logger.info(f"   üöÄ {file_type}: {file_path} (–¥–ª—è API/—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞)")
        logger.info("=" * 70)
        
        return exported_files


def create_optimized_readme():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π README —Ñ–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö"""
    readme_content = """# HLS Checker - –§–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã

## üìä –û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤

### CSV —Ñ–∞–π–ª—ã (–¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤)

1. **hls_channels_final_stats_YYYYMMDD_HHMMSS.csv** - –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º
   - –≤—Ä–µ–º—è_–Ω–∞—á–∞–ª–∞_—Å–µ—Å—Å–∏–∏ / –≤—Ä–µ–º—è_–æ–∫–æ–Ω—á–∞–Ω–∏—è_—Å–µ—Å—Å–∏–∏: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
   - –Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞–Ω–∞–ª–∞: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–≥–æ –∫–∞–Ω–∞–ª–∞
   - –ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
   - –æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë: –û–±—â–∏–π –æ–±—ä–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
   - —Å—Ä–µ–¥–Ω—è—è_—Å–∫–æ—Ä–æ—Å—Ç—å_–ú–ë_—Å: –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏

2. **hls_global_summary_YYYYMMDD_HHMMSS.csv** - –û–±—â–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º
   - –æ–±—â–µ–µ_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–∞–Ω–∞–ª–æ–≤: –í—Å–µ–≥–æ –∫–∞–Ω–∞–ª–æ–≤ –≤ –ø—Ä–æ–≤–µ—Ä–∫–µ
   - –æ–±—â–∏–π_–ø—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: –û–±—â–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
   - –æ–±—â–∏–π_–æ–±—ä–µ–º_–ú–ë: –û–±—â–∏–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤

### JSON —Ñ–∞–π–ª—ã (–¥–ª—è API –∏ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞)

1. **hls_api_report_YYYYMMDD_HHMMSS.json** - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π API –æ—Ç—á–µ—Ç
   - session: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
   - summary: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
   - channels: –ú–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º
   - analytics: –õ—É—á—à–∏–π –∏ —Ö—É–¥—à–∏–π –∫–∞–Ω–∞–ª—ã

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –î–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
–û—Ç–∫—Ä–æ–π—Ç–µ CSV —Ñ–∞–π–ª—ã –≤ Excel/Google Sheets –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π.

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ JSON API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –¥–∞—à–±–æ—Ä–¥–∞–º–∏ –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏.

### Python –ø—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å JSON
```python
import json

# –ó–∞–≥—Ä—É–∑–∫–∞ API –æ—Ç—á–µ—Ç–∞
with open('data/json/hls_api_report_20240904_201200.json', 'r', encoding='utf-8') as f:
    api_data = json.load(f)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏
summary = api_data['summary']
print(f"–û–±—â–∏–π —É—Å–ø–µ—Ö: {summary['overall_success_rate']}%")

# –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–æ–≤
for channel in api_data['channels']:
    print(f"{channel['name']}: {channel['stats']['success_rate']}%")
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞
```
data/
‚îú‚îÄ‚îÄ csv/           # CSV –¥–ª—è Excel/–º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
‚îú‚îÄ‚îÄ json/          # JSON –¥–ª—è API/—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
‚îî‚îÄ‚îÄ README.md      # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```
"""
    
    readme_path = DATA_DIR / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    logger.info(f"üìñ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π README —Å–æ–∑–¥–∞–Ω: {readme_path}")
    return readme_path